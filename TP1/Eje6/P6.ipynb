{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f661d5-282d-4911-82e0-e8cca9c434f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def tokenizador(text):\n",
    "    text = text.lower()\n",
    "    intab = \"áéíóú\"\n",
    "    outtab = \"aeiou\"\n",
    "    str = text\n",
    "    trantab = str.maketrans(intab, outtab)\n",
    "    normalizado = str.translate(trantab)\n",
    "    normalizado = re.sub(r'[^a-z0-9 ]','', normalizado)\n",
    "    tokens = normalizado.split(\" \")\n",
    "    if \"\" in tokens:\n",
    "        while \"\" in tokens:\n",
    "            tokens.remove(\"\")\n",
    "    return tokens\n",
    "\n",
    "def contador(terms, tokens):\n",
    "    for token in tokens:\n",
    "        if token in terms:\n",
    "            terms[token] += 1\n",
    "        else:\n",
    "            terms[token] =  1\n",
    "    return terms\n",
    "\n",
    "terms = {}\n",
    "\n",
    "with open(\"Quijote.txt\") as archivo:\n",
    "    for linea in archivo:\n",
    "        tokens=tokenizador(linea)\n",
    "        terms = contador(terms,tokens)\n",
    "\n",
    "\n",
    "sorted_terms = dict(sorted(terms.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "sorted_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303b9c5-8567-4670-a4c8-7a0dbf360cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos={\"words\":[],\"rank\":[],\"freq\":[]}\n",
    "rank = 1\n",
    "terms_total = 0\n",
    "with open(\"terminosQuijote.txt\", \"w\") as f:\n",
    "    for term, info in sorted_terms.items():\n",
    "        datos[\"words\"].append(term)\n",
    "        datos[\"rank\"].append(rank)\n",
    "        datos[\"freq\"].append(info)\n",
    "        rank += 1\n",
    "        terms_total += info\n",
    "        f.write(f\"{term} {info}\\n\")\n",
    "\n",
    "df = pd.DataFrame(datos)\n",
    "x = np.log(datos[\"rank\"])\n",
    "y = np.log(datos[\"freq\"])\n",
    "fit = np.polyfit(x,y,1)\n",
    "polynomial = np.poly1d(fit)\n",
    "y_estimated = np.exp(polynomial(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2290a7-fecc-4bd5-846f-90434c19e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(datos)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ff32a-818c-4417-9919-f7d4a03ab677",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"rank\"],df[\"freq\"], linestyle='solid')\n",
    "plt.title('Ley de Zipf')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ecfda-09f4-446d-b106-2c6f7367cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(df[\"rank\"],df[\"freq\"], linestyle='solid')\n",
    "plt.loglog(df[\"rank\"],y_estimated, linestyle='solid', label = \"estimado\")\n",
    "plt.title('Ley de Zipf log')\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666da4fe-4f52-4eb7-940b-b911b7e88fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_10por = int(0.1*terms_total)\n",
    "terms_20por = int(0.2*terms_total)\n",
    "terms_30por = int(0.3*terms_total)\n",
    "terms_10 = []\n",
    "terms_20 = []\n",
    "terms_30 = []\n",
    "print(terms_10por)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c660aaa7-4bd5-41ba-930f-59563ebdf933",
   "metadata": {},
   "outputs": [],
   "source": [
    "for term, info in sorted_terms.items():\n",
    "    if terms_10por>0:\n",
    "        terms_10.append(term)\n",
    "        terms_10por -=info\n",
    "    if terms_20por>0:\n",
    "        terms_20.append(term)\n",
    "        terms_20por -=info\n",
    "    if terms_30por>0:\n",
    "        terms_30.append(term)\n",
    "        terms_30por -=info\n",
    "stops = set(stopwords.words('spanish'))\n",
    "\n",
    "cant_term10 = len(terms_10)\n",
    "cant_term20 = len(terms_20)\n",
    "cant_term30 = len(terms_30)\n",
    "\n",
    "pruning_10_percent = 0\n",
    "pruning_20_percent = 0\n",
    "pruning_30_percent = 0\n",
    "\n",
    "print(terms_10)\n",
    "print(terms_20)\n",
    "print(terms_30)\n",
    "\n",
    "pruning_terms_10 = []\n",
    "pruning_terms_20 = []\n",
    "pruning_terms_30 = []\n",
    "\n",
    "for term in terms_10:\n",
    "    if term in stops:\n",
    "        pruning_10_percent += 1\n",
    "    else: \n",
    "        pruning_terms_10.append(term)\n",
    "\n",
    "for term in terms_20:\n",
    "    if term in stops:\n",
    "        pruning_20_percent += 1\n",
    "    else: \n",
    "        pruning_terms_20.append(term)\n",
    "\n",
    "for term in terms_30:\n",
    "    if term in stops:\n",
    "        pruning_30_percent += 1\n",
    "    else: \n",
    "        pruning_terms_30.append(term)\n",
    "\n",
    "pruning_terms_10.extend(term for term in terms_10 if term not in stops)\n",
    "pruning_terms_20.extend(term for term in terms_20 if term not in stops)\n",
    "pruning_terms_30.extend(term for term in terms_30 if term not in stops)\n",
    "\n",
    "print(\"porcentaje de la poda coincide con palabras vacías 10%\", pruning_10_percent/cant_term10*100)\n",
    "print(terms_10)\n",
    "print(pruning_terms_10)\n",
    "print(\"porcentaje de la poda coincide con palabras vacías 20%\", pruning_20_percent/cant_term20*100)\n",
    "print(terms_20)\n",
    "print(pruning_terms_20)\n",
    "print(\"porcentaje de la poda coincide con palabras vacías 30%\", pruning_30_percent/cant_term30*100)\n",
    "print(terms_30)\n",
    "print(pruning_terms_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675410e5-7357-47a3-ada6-927e793490f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = fit[0]\n",
    "b = fit[1]\n",
    "c= np.exp(b)\n",
    "beta = -1*m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff3b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f6407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "print(beta)\n",
    "# Calcular la posición de la palabra correspondiente al 10% del vocabulario\n",
    "totalStops = len(sorted_terms)\n",
    "print(totalStops)\n",
    "posicion_10porc = math.ceil((totalStops * 0.1)**(1 / beta))\n",
    "print(posicion_10porc)\n",
    "\n",
    "# Obtener la frecuencia de la palabra en la posición correspondiente\n",
    "frecuencia_10porc = list(sorted_terms.values())[posicion_10porc]\n",
    "\n",
    "# Calcular la cantidad de palabras en el 10% del vocabulario\n",
    "cantidad_palabras_10porc = len([f for f in sorted_terms.values() if f >= frecuencia_10porc])\n",
    "\n",
    "print(\"Cantidad de palabras en el 10% del vocabulario:\", cantidad_palabras_10porc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8578cfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2240bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
