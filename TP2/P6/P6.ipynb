{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenizador(text):\n",
    "    text = text.lower()\n",
    "    intab = \"áéíóú\"\n",
    "    outtab = \"aeiou\"\n",
    "    str = text\n",
    "    trantab = str.maketrans(intab, outtab)\n",
    "    normalizado = str.translate(trantab)\n",
    "    normalizado = re.sub(r'[^a-z0-9 ]','', normalizado)\n",
    "    tokens = normalizado.split(\" \")\n",
    "    if \"\" in tokens:\n",
    "        while \"\" in tokens:\n",
    "            tokens.remove(\"\")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def idf(terms):\n",
    "    idf = {}\n",
    "    for term in terms:\n",
    "        idf[term] = math.log(terms[term][\"cf\"]/ terms[term][\"df\"])\n",
    "    return idf\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_score(index,queriText, idf):\n",
    "    score = {}\n",
    "    queri = tokenizador(queriText)\n",
    "    for q in queri:\n",
    "        for path,terms in index.items():\n",
    "            if q in terms:\n",
    "                tf = terms[q] / len(terms)\n",
    "                if path in score:\n",
    "                    score[path] +=  tf*idf[q]\n",
    "                else:\n",
    "                    score[path] = tf*idf[q] \n",
    "    return score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contadorTerms(terms, tokens):\n",
    "    for token in tokens:\n",
    "        if token in terms:\n",
    "            terms[token] += 1\n",
    "        elif len(token)>2 and len(token)<20:\n",
    "            terms[token] = 1\n",
    "    return terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def remove_sportsworld(terms):\n",
    "    dic = {}\n",
    "    stopsSp = set(stopwords.words('spanish'))\n",
    "    stopsEn = set(stopwords.words('english'))\n",
    "    for term in terms:\n",
    "        if term not in stopsSp and term not in stopsEn:\n",
    "            dic[term] = terms[term]\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_dir = \"wiki-small/\"\n",
    "\n",
    "\n",
    "def enumerate_html_files(directory):\n",
    "    document_id = 1\n",
    "    index = {}\n",
    "    terms = {}\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            dic = {}\n",
    "            tokens = {}\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as html_file:\n",
    "                termsAux = {}\n",
    "                content = html_file.read()\n",
    "                tokens =tokenizador(content)\n",
    "                dic = contadorTerms(dic,tokens)\n",
    "                termsAux = contadorTerms(termsAux,tokens)\n",
    "                dic = remove_sportsworld(dic)\n",
    "                index[file_path] = dic\n",
    "                for term, aux in termsAux.items():\n",
    "                    if term in terms:\n",
    "                        terms[term][\"cf\"] += aux\n",
    "                        terms[term][\"df\"] += 1\n",
    "                    else:\n",
    "                        terms[term] = {\"cf\": aux, \"df\": 1}\n",
    "    return index, terms\n",
    "\n",
    "index,terms = enumerate_html_files(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = idf(terms)\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "queri = 'software'\n",
    "score=get_score(index,queri,idf )\n",
    "score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_terms = sorted(score.items(), key=lambda item: item[1], reverse=True)\n",
    "sorted_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankTfIdf = [tupla[0] for tupla in sorted_terms]\n",
    "rankTfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init()\n",
    "\n",
    "indexer = pt.FilesIndexer(\"./index\", verbose=True, overwrite=True, meta={\"docno\":20, \"filename\":512})\n",
    "indexref =indexer.index(root_dir)\n",
    "index = pt.IndexFactory.of(indexref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "br =  pt.BatchRetrieve(index, num_results=50, wmodel=\"TF_IDF\", metadata=[\"filename\"])\n",
    "results = br.search(queri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = np.array(results[\"filename\"])\n",
    "tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearmancoefficient, datos = spearmanr(tfidf[:5], rankTfIdf[:5])\n",
    "print(\"Coeficiente de correlación de Spearman 5 documentos:\", spearmancoefficient,)\n",
    "\n",
    "spearmancoefficient, datos = spearmanr(tfidf[:10], rankTfIdf[:10])\n",
    "print(\"Coeficiente de correlación de Spearman 10 documentos:\", spearmancoefficient,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
